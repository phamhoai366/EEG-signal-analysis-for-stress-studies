{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spkit\n",
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "from numpy import genfromtxt\n",
    "import csv\n",
    "import spkit as sp\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Reshape, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, \\\n",
    "    confusion_matrix, balanced_accuracy_score, precision_recall_curve, matthews_corrcoef, roc_curve, jaccard_score, \\\n",
    "    hamming_loss, fbeta_score, precision_recall_fscore_support, zero_one_loss, average_precision_score\n",
    "from sklearn.metrics import cohen_kappa_score, roc_auc_score, mean_squared_error, auc\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZE DATA SAM40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tập dữ liệu này trình bày một tập hợp dữ liệu điện não đồ (EEG) được ghi lại từ 40 đối tượng (nữ: 14, nam: 26, tuổi trung bình: 21,5 tuổi). Thí nghiệm chủ yếu được thực hiện để theo dõi mức độ căng thẳng ngắn hạn gây ra ở một cá nhân trong khi thực hiện các nhiệm vụ khác nhau như kiểm tra từ màu Stroop, giải các câu hỏi số học, xác định hình ảnh phản chiếu đối xứng và trạng thái thư giãn. Các nhiệm vụ riêng lẻ được thực hiện trong 25 giây và ba thử nghiệm được ghi lại cho từng nhiệm vụ riêng lẻ. Điện não đồ được ghi lại từ 32 kênh (cộng với tham chiếu CMS/DRL) với dải động +/- 4,12 mV, với độ phân giải 0,51 µV/bit và phạm vi 14 bit. Điện não đồ được lấy mẫu ở 128 SPS (1024 Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from .mat file\n",
    "mat_data_sam40 = scipy.io.loadmat('/content/drive/MyDrive/Colab_Notebooks/Thesis/Data/SAM_40/raw_data/Arithmetic_sub_10_trial1.mat')\n",
    "print('mat_data: ', mat_data_sam40, '\\nlen mat_data: ',  len(mat_data_sam40))\n",
    "print(mat_data_sam40['Data'])\n",
    "print(len(mat_data_sam40['Data']))\n",
    "print(mat_data_sam40['Data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to pandas DataFrame\n",
    "df = pd.DataFrame(mat_data_sam40['Data'])\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from .mat file\n",
    "mat_data_sam40 = scipy.io.loadmat('/content/drive/MyDrive/Colab_Notebooks/Thesis/Data/SAM_40/raw_data/Arithmetic_sub_10_trial1.mat')\n",
    "\n",
    "# Convert data to pandas DataFrame and transpose it\n",
    "df = pd.DataFrame(mat_data_sam40['Data']).T\n",
    "\n",
    "# Create time stamps based on the sampling frequency (128 Hz)\n",
    "time_stamps = pd.date_range(start='1/1/2000', periods=df.shape[0], freq='7.8125ms')\n",
    "\n",
    "# Plot each feature as a separate subplot\n",
    "fig, axes = plt.subplots(nrows=df.shape[1], ncols=1, figsize=(15, 50))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.plot(time_stamps, df.iloc[:,i])\n",
    "    ax.set_ylabel('Feature {}'.format(i+1))\n",
    "\n",
    "# Set x-axis label to time and adjust the layout\n",
    "axes[-1].set_xlabel('Time')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AZIMUTHAL EQUIDISTANT PROJECTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha = (8,13)\n",
    "beta = (12,30)\n",
    "gamma = (30, 45)\n",
    "\n",
    "def get_fft(snippet):\n",
    "    Fs = 128;  # sampling rate\n",
    "    #Ts = len(snippet)/Fs/Fs; # sampling interval\n",
    "    snippet_time = len(snippet)/Fs\n",
    "    Ts = 1.0/Fs; # sampling interval\n",
    "    t = np.arange(0,snippet_time,Ts) # time vector\n",
    "\n",
    "    # ff = 5;   # frequency of the signal\n",
    "    # y = np.sin(2*np.pi*ff*t)\n",
    "    y = snippet\n",
    "#     print('Ts: ',Ts)\n",
    "#     print(t)\n",
    "#     print(y.shape)\n",
    "    n = len(y) # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n/Fs\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(n//2)] # one side frequency range\n",
    "\n",
    "    Y = np.fft.fft(y)/n # fft computing and normalization\n",
    "    Y = Y[range(n//2)]\n",
    "    #Added in: (To remove bias.)\n",
    "    #Y[0] = 0\n",
    "    return frq,abs(Y)\n",
    "#f,Y = get_fft(np.hanning(len(snippet))*snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average power in the alpha, beta, and gamma bands\n",
    "def theta_alpha_beta_averages(f,Y):\n",
    "    gamma_range = (30, 45)\n",
    "    alpha_range = (8, 12)\n",
    "    beta_range = (12, 30)\n",
    "\n",
    "\n",
    "    gamma = Y[(f>gamma_range[0]) & (f<=gamma_range[1])].mean()\n",
    "    alpha = Y[(f>alpha_range[0]) & (f<=alpha_range[1])].mean()\n",
    "    beta = Y[(f>beta_range[0]) & (f<=beta_range[1])].mean()\n",
    "    return gamma, alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Cartesian coordinates to spherical\n",
    "def cart2sph(x, y, z):\n",
    "    x2_y2 = x ** 2 + y ** 2\n",
    "    r = math.sqrt(x2_y2 + z ** 2)  # r\n",
    "    elev = math.atan2(z, math.sqrt(x2_y2))  # Elevation\n",
    "    az = math.atan2(y, x)  # Azimuth\n",
    "    return r, elev, az\n",
    "\n",
    "# Transform polar coordinates to Cartesian\n",
    "def pol2cart(theta, rho):\n",
    "    return rho * math.cos(theta), rho * math.sin(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_steps(samples,frame_duration,overlap):\n",
    "    '''\n",
    "    in:\n",
    "    samples - number of samples in the session\n",
    "    frame_duration - frame duration in seconds\n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "\n",
    "    out: list of tuple ranges\n",
    "    '''\n",
    "    #steps = np.arange(0,len(df),frame_length)\n",
    "    Fs = 128\n",
    "    i = 0\n",
    "    intervals = []\n",
    "    samples_per_frame = Fs * frame_duration\n",
    "    while i+samples_per_frame <= samples:\n",
    "        intervals.append((i,i+samples_per_frame))\n",
    "        i = i + samples_per_frame - int(samples_per_frame*overlap)\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frames(df,frame_duration):\n",
    "    '''\n",
    "    in: dataframe or array with all channels, frame duration in seconds\n",
    "    out: array of theta, alpha, beta averages for each probe for each time step\n",
    "        shape: (n-frames,m-probes,k-brainwave bands)\n",
    "    '''\n",
    "    Fs = 128.0\n",
    "    frame_length = Fs*frame_duration\n",
    "    frames = []\n",
    "    steps = make_steps(len(df),frame_duration,overlap)\n",
    "    for i,_ in enumerate(steps):\n",
    "        frame = []\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else:\n",
    "            for channel in df.columns:\n",
    "                snippet = np.array(df.loc[steps[i][0]:steps[i][1],int(channel)])\n",
    "                f,Y =  get_fft(snippet)\n",
    "                gamma, alpha, beta = theta_alpha_beta_averages(f,Y)\n",
    "                frame.append([gamma, alpha, beta])\n",
    "\n",
    "        frames.append(frame)\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def azim_proj(pos):\n",
    "    \"\"\"\n",
    "    Computes the Azimuthal Equidistant Projection of input point in 3D Cartesian Coordinates.\n",
    "    Imagine a plane being placed against (tangent to) a globe. If\n",
    "    a light source inside the globe projects the graticule onto\n",
    "    the plane the result would be a planar, or azimuthal, map\n",
    "    projection.\n",
    "\n",
    "    :param pos: position in 3D Cartesian coordinates\n",
    "    :return: projected coordinates using Azimuthal Equidistant Projection\n",
    "    \"\"\"\n",
    "    [r, elev, az] = cart2sph(pos[0], pos[1], pos[2])\n",
    "    return pol2cart(az, math.pi / 2 - elev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_images(locs, features, n_gridpoints, normalize=True,\n",
    "               augment=False, pca=False, std_mult=0.1, n_components=2, edgeless=False):\n",
    "    \"\"\"\n",
    "    Generates EEG images given electrode locations in 2D space and multiple feature values for each electrode\n",
    "\n",
    "    :param locs: An array with shape [n_electrodes, 2] containing X, Y\n",
    "                        coordinates for each electrode.\n",
    "    :param features: Feature matrix as [n_samples, n_features]\n",
    "                                Features are as columns.\n",
    "                                Features corresponding to each frequency band are concatenated.\n",
    "                                (alpha1, alpha2, ..., beta1, beta2,...)\n",
    "    :param n_gridpoints: Number of pixels in the output images\n",
    "    :param normalize:   Flag for whether to normalize each band over all samples\n",
    "    :param augment:     Flag for generating augmented images\n",
    "    :param pca:         Flag for PCA based data augmentation\n",
    "    :param std_mult     Multiplier for std of added noise\n",
    "    :param n_components: Number of components in PCA to retain for augmentation\n",
    "    :param edgeless:    If True generates edgeless images by adding artificial channels\n",
    "                        at four corners of the image with value = 0 (default=False).\n",
    "    :return:            Tensor of size [samples, colors, W, H] containing generated\n",
    "                        images.\n",
    "    \"\"\"\n",
    "    feat_array_temp = []\n",
    "    nElectrodes = locs.shape[0]     # Number of electrodes\n",
    "    print(\"nElectrodes: \",nElectrodes)\n",
    "    print(\"feature.shape: \",features.shape)\n",
    "    # Test whether the feature vector length is divisible by number of electrodes\n",
    "    assert features.shape[1] % nElectrodes == 0\n",
    "    n_colors = features.shape[1] // nElectrodes\n",
    "    for c in range(int(n_colors)):\n",
    "        feat_array_temp.append(features[:, c * nElectrodes : nElectrodes * (c+1)])\n",
    "    if augment:\n",
    "        if pca:\n",
    "            for c in range(n_colors):\n",
    "                feat_array_temp[c] = augment_EEG(feat_array_temp[c], std_mult, pca=True, n_components=n_components)\n",
    "        else:\n",
    "            for c in range(n_colors):\n",
    "                feat_array_temp[c] = augment_EEG(feat_array_temp[c], std_mult, pca=False, n_components=n_components)\n",
    "    nSamples = features.shape[0]\n",
    "    # Interpolate the values\n",
    "    grid_x, grid_y = np.mgrid[\n",
    "                     min(locs[:, 0]):max(locs[:, 0]):n_gridpoints*1j,\n",
    "                     min(locs[:, 1]):max(locs[:, 1]):n_gridpoints*1j\n",
    "                     ]\n",
    "    temp_interp = []\n",
    "    for c in range(n_colors):\n",
    "        temp_interp.append(np.zeros([nSamples, n_gridpoints, n_gridpoints]))\n",
    "    # Generate edgeless images\n",
    "    if edgeless:\n",
    "        min_x, min_y = np.min(locs, axis=0)\n",
    "        max_x, max_y = np.max(locs, axis=0)\n",
    "        locs = np.append(locs, np.array([[min_x, min_y], [min_x, max_y],[max_x, min_y],[max_x, max_y]]),axis=0)\n",
    "        for c in range(n_colors):\n",
    "            feat_array_temp[c] = np.append(feat_array_temp[c], np.zeros((nSamples, 4)), axis=1)\n",
    "    # Interpolating\n",
    "    for i in range(nSamples):\n",
    "        for c in range(n_colors):\n",
    "            temp_interp[c][i, :, :] = griddata(locs, feat_array_temp[c][i, :], (grid_x, grid_y),\n",
    "                                    method='cubic', fill_value=np.nan)\n",
    "        print('Interpolating {0}/{1}\\r'.format(i+1, nSamples), end='\\r')\n",
    "    # Normalizing\n",
    "    for c in range(n_colors):\n",
    "        if normalize:\n",
    "            temp_interp[c][~np.isnan(temp_interp[c])] = scale(temp_interp[c][~np.isnan(temp_interp[c])])\n",
    "        temp_interp[c] = np.nan_to_num(temp_interp[c])\n",
    "    return np.swapaxes(np.asarray(temp_interp), 0, 1)     # swap axes to have [samples, colors, W, H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_pipeline(file_names,labels,image_size,frame_duration,overlap):\n",
    "    '''\n",
    "    IN:\n",
    "    file_names - list of strings for each input file (one for each subject)\n",
    "    labels - list of labels for each\n",
    "    image_size - int size of output images in form (x, x)\n",
    "    frame_duration - time length of each frame (seconds)\n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "\n",
    "    OUT:\n",
    "    X: np array of frames (unshuffled)\n",
    "    y: np array of label for each frame (1 or 0)\n",
    "    '''\n",
    "    ##################################\n",
    "    ###Still need to do the overlap###!!!\n",
    "    ##################################\n",
    "\n",
    "    Fs = 128   #sampling rate\n",
    "    frame_length = Fs * frame_duration\n",
    "\n",
    "    print('Generating training data...')\n",
    "\n",
    "\n",
    "    for i, file in enumerate(file_names):\n",
    "        print ('Processing session: ',file, '. (',i+1,' of ',len(file_names),')')\n",
    "        data = genfromtxt(file, delimiter=',').T\n",
    "        # df = pd.DataFrame(data)\n",
    "        df = pd.DataFrame(data[:, 1:])\n",
    "\n",
    "        X_0 = make_frames(df,frame_duration)\n",
    "        #steps = np.arange(0,len(df),frame_length)\n",
    "        X_1 = X_0.reshape(len(X_0),32*3)\n",
    "\n",
    "        images = gen_images(np.array(locs_2d),X_1, image_size, normalize=False)\n",
    "        images = np.swapaxes(images, 1, 3)\n",
    "        print(len(images), ' frames generated with label ', labels[i], '.')\n",
    "        print('\\n')\n",
    "        if i == 0:\n",
    "            X = images\n",
    "            y = np.ones(len(images))*labels[0]\n",
    "        else:\n",
    "            X = np.concatenate((X,images),axis = 0)\n",
    "            y = np.concatenate((y,np.ones(len(images))*labels[i]),axis = 0)\n",
    "\n",
    "\n",
    "    return X, np.array(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
